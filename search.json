[
  {
    "objectID": "index.html#abstract",
    "href": "index.html#abstract",
    "title": "ORD Proposal: Open Time Series",
    "section": "Abstract",
    "text": "Abstract\nBecause publications of public data providers focus on a broader audience, their datasets are often not convenient to use for academic research. As a result, data sourcing processes are implemented redundantly across research projects and institutions, often in a not entirely automated, possibly error-prone way. The Open Time Series project addresses this problem by publishing fully reproducible routines to create time series from publicly available data. Doing so yields valuable results: First, the publication of thousands of well-tested, machine-readable time series and their metadata will reduce the data sourcing burden and improve data quality within the time series analysis and economic research communities that use Swiss data. Second, the community approach we employ, the exemplary character and the inclusive approach of our open source software promise to have spillover effects to other research communities in the longer run. The network of the Swiss Economic Institute (KOF) leverages the impact of our project through exchange on our learnings with data providers such as the Federal Statistical Office (FSO), the Swiss National Bank (SNB), the Swiss Secretariat of Economic Affairs (SECO) and cantonal statistical offices. Finally, the inclusion of the Open Time Series framework and datasets into teaching advances Open Research Data (ORD) principles and helps the next generation of public servants to become Open Science leaders who are familiar with Swiss data landscape.\n\n\n\n\n\n\n\nFull title\nOpen Time Series - An Open Framework to Create Scientific Grade Time Series Datasets from Public Data\n\n\n\n\n\n\nKeywords\nOpen Data, Official Statistics, Time Series Analysis, Data Literacy, Automation, Machine Readability, Community"
  },
  {
    "objectID": "intro.html#problem-statement",
    "href": "intro.html#problem-statement",
    "title": "1  Introduction",
    "section": "1.1 Problem Statement",
    "text": "1.1 Problem Statement\nEven though most official statistics in Switzerland are publicly available, data publications from regional and federal public data providers often lack machine readability. Therefore, these data publications are not convenient for academic researchers and other groups that ingest public data frequently.\nIn the field of economics, for example, intertemporal comparisons play an important role. This type of research implies regular and timely sourcing of data. Traditional data publications are often unsuitable1 for the scientific consumer, as modern economic (forecasting) models make use of hundreds or thousands of variables stemming from a large range of datasets. Particularly, researchers who source a large amount of time series data from different providers are impacted by the substantial difference in the pace of the digital transformation across providers or the differences that exist even between departments of the same providers.\nThough application programming interfaces (APIs) from the official providers have led to great improvements in the machine readability of public data, machine readability is not homogenous across datasets. The proposed project mitigates the machine readability issue by not only publishing time series data created from a fully transparent process, but also by providing an open technical processing framework. Our framework eases the data sourcing and quality control burden and, at the same time, encourages researchers to contribute time series datasets of their own. In addition, the Open Time Series project establishes a steady and hands-on exchange between regional and federal data providers and the community of academic users of public data."
  },
  {
    "objectID": "intro.html#background-and-motivation",
    "href": "intro.html#background-and-motivation",
    "title": "1  Introduction",
    "section": "1.2 Background and Motivation",
    "text": "1.2 Background and Motivation\nAlthough we aim at extending the approach suggested in this proposal to other fields in the future, this Explore proposal focuses on our ‘home court’ disciplines of public statistics and empirical economics. We are confident that our strong network in both fields will leverage our initial push sufficiently to give the impact of the Open Time Series project a great chance to spill over to other communities. The following sections introduce our background and explain how the proposed project helps the economics, forecasting and open data communities.\n\nTime Series Analysis, Forecasting and Data Science in Economics\nTime Series analysis continues to play an important role in many strands of modern empirical economics: Economic forecasting and its evaluation, studies of shock absorption, and many other econometric modeling exercises require data that allow intertemporal comparison. Modern models often use hundreds, or even thousands, of time series.\nEven though machine readability of publicly available data has improved in Switzerland, thanks to great efforts led by the Swiss Federal Statistical Office (FSO), researchers are confronted with a data publication mindset that is focused on the wider public and hence on the most recent wave of data. As a consequence, variable names or features may change over time, and minor errors may simply be corrected on an ad hoc basis or with the next publication - even in datasets that are already available through an application programming interface. In combination with different degrees of machine readability across different providers of public data, the issues mentioned above can lead to two very heterogeneous situations when it comes to automated data sourcing, particularly for those researchers who need large amounts of data from various providers. Another aspect in which the focus of public data providers differs from academic research is the importance of readily available, so-called real-time vintages. Vintages can be seen as versions of time series that allow researchers to work with past publications even after the official version has been revised. While versioned time series are inevitable for many research exercises, such as the evaluation of forecasts based on the data that had been available when the forecast was made, multiple official versions are harder to communicate to the broader public and induce higher data management costs.\nOur motivation is to help the time series community immediately while larger organizations focus on different challenges in their own digital transformation and often have different migration paths and schedules. We intend to do so by not only open-sourcing a framework to create scientific grade time series from official statistics, but also publishing our framework in the most transparent way possible:\n\n\n\n\n\n\nMotivation through Immediate Impact\n\n\n\n\nWe focus on thorough documentation that involves the community.\nWe provide comprehensive application examples facilitating transfer to one’s own needs, making many thousand proven time series publicly available.\nMachine-readable data and the Open Time Series automation framework substantially facilitate hosting a versioned time series database.\nWe have an infrastructure-as-code approach and share precise information on how to set up an environment that is capable of running our framework.\n\n\n\n\n\nOfficial Statistics and Public Data\nOur commitment to regular publication of data-driven indicators designed for intertemporal comparison and our leading role in the community ensure the sustainability of the Open Time Series project. The strong empirical focus of the academic research at the KOF Swiss Economic Institute (KOF) provides great synergies with the production of forecasts and indicators, many of which rely on publicly available data provided by Swiss federal and regional administrations. The Open Time Series project bridges the described gap between official statistics and academic economic research and strenghtens the connections between these communities in Switzerland.\n\n\n\n\n\nThe KOF Economic Barometer is a forward-looking indicator (FLI) for the Swiss economy. It is well accepted in Switzerland and used as the official FLI for Switzerland by the International Monetary Fund (IMF). source: KOF Swiss Economic Institute, ETH Zurich.\n\n\n\n\nIn addition to its popular indicators for the Swiss economy, KOF makes a wide array of fine-grained, sector-specific time series publicly available. Per January 2024, the KOF time series explorer made more than 31’000 time series publicly available in human-browsable and machine-readable fashion2. This experience with the regular publication of economic data, the production of indicators, economic forecasting and KOF’s task of monitoring the Swiss economy makes us relate further to the needs and challenges of official statistics. Through our steady exchange with key data providers and data consumers such as the Swiss National Bank (SNB), the Swiss Federal Statistical Office (FSO), the Secretariat of Economic Affairs (SECO), the State Secretariat of Education, Research, and Innovation (SERI) and the Swiss cantonal statistical offices, we are aware that other institutions have often cumbersome, semi-automatic data sourcing processes to process publicly available data that are highly redundant across institutions. Hence, we will not only open-source our implementation but also commit to put in substantial additional effort to make our solution inclusive and transparent to others. This will impact the community in three sustainable ways:\n\n\n\n\n\n\nMotivation through Sustainable Impact\n\n\n\ni.) We help reduce redundant implementation of data sourcing routines across publicly-financed institutions\nii.) We establish source code as an unambiguous channel that is understood across institutions and fields in order to communicate the needs of the research community in a highly dynamic environment\niii.) We develop a blueprint for data consumption in a collaborative fashion, increasing the commitment of involved collaborators\n\n\nThe feedback generated in the process is a core strategy of the Open Time Series project that we validated in talks with official data providers in advance of this proposal. Communication through code is unambiguous and reproducible and helps to communicate needs across fields, perspectives, and focuses.\nFurther concrete steps could be the integration of FSO experts into teaching or the use of Swiss data in academic teaching and open-source software packages.\nThe Open Time Series project can build on an established network for great outreach and at the same time, produce an entirely new group of publicly available, scientific use grade time series datasets. While the vast majority of the existing, aforementioned KOF time series stem from KOF’s own business tendency surveys, the Open Time Series project facilitates research use of additional data stemming from other providers, most notably the Swiss Federal Statistical Office (FSO). In addition to such major sources of macroeconomic data, the Open Time Series project helps to make the maintenance of time series from smaller, independent providers more sustainable. Independent community maintainers can use the Open Time Series framework to process datasets of their needs stemming from smaller providers. The modular approach of our framework does not only adding new datasets easily but also to exchange maintainers at the dataset level in case certain a previous dataset stakeholder cannot keep do their maintenance effort. In addition, our approach allows researchers to publicly archive data and reproduce results more easily."
  },
  {
    "objectID": "ord_plan.html#wp0-coordination-and-planning",
    "href": "ord_plan.html#wp0-coordination-and-planning",
    "title": "2  ORD Project Plan",
    "section": "2.1 WP0: Coordination and Planning",
    "text": "2.1 WP0: Coordination and Planning\n\n\n\n\n\n\n\n\n\nActivities and Research Questions\n\n\n\nActivity 0.1: Meetings with Data Provider Management and Operations\nActivity 0.2: RSEED Meetup Series\nRQ 0.1: Which channels and formats work to keep the dialogue active and sustainable?\nRQ 0.2: How can we integrate usage of publicly available data into teaching?\n\n\nDuring the starting stage of our project, we coordinate with major public data providers and involve data sources. We will do this to establish and maintain active, lively communication between public data providers and the scientific community.\n\nPublicly available economic data provided by the Federal Statistical Office (FSO), the Secretariat of Economic Affairs (SECO), the Swiss National Bank (SNB), and regional Statistical Offices are important sources for economic research and monitoring of the Swiss economy. To develop an ORD spirit and a community of data providers and scientific users of the data, it is crucial to involve these public institutions early on. Early dialogue helps to avoid redundancies with existing data community initiatives and to develop a common understanding of open data, machine readability and datasets of priority.\nOne core idea is to leverage existing, general investment into publicly available economic data through integration of public data into academic teaching to strengthen the connection between public administration and academia. In the sense of our open source spirit, we look to add further Research Data Management (RDM) aspects to our existing, freely reusable, CC-BY licensed online teaching.\nTo explore how to effectively use the joint expertise of public data providers, domain experts, data stewards of the ETH domain, and data engineers, we will launch a series of monthly workshops early in the process. The workshops are designed to foster inclusive, expert discussions through publicly pre-circulated content. We are working to integrate our workshop series into the academic curriculum at ETH, but we keep the series open to interested participants beyond academia."
  },
  {
    "objectID": "ord_plan.html#wp1-make-data-processing-framework-inclusive",
    "href": "ord_plan.html#wp1-make-data-processing-framework-inclusive",
    "title": "2  ORD Project Plan",
    "section": "2.2 WP1: Make Data Processing Framework Inclusive",
    "text": "2.2 WP1: Make Data Processing Framework Inclusive\n\n\n\n\n\n\n\n\n\nActivities and Research Questions\n\n\n\nActivity 1.1: Implement Core Library for Standardized Data Processing\nActivity 1.2: Modularize Provider Specific Data Ingestion Processes\nActivity 1.3: Document Processing Framework\nRQ 1.1: What are the key components of a framework to ingest data for scientific use?\nRQ 1.2: How can we isolate idiosyncrasies for optimal reuse of code?\nRQ 1.3: What makes documentation of open source software and open research data inclusive?\n\n\n\nIn Work Package 1 (WP1), we lay the technical foundation for turning KOF Swiss Economic Institute’s (KOF) existing production process of macroeconomic time series into an open-source framework that creates publicly available, machine-readable, scientific-grade time series in a fully reproducible fashion. Our approach uses open-source software licenses that are free of license costs and aims to publish not only the resulting time series data but also the technical framework and infrastructure setup. This ensures reproducibility and helps comply with FAIR principles. Thanks to our infrastructure-as-code approach, we can publish information on an ideal runtime environment to help others operate their own instance of the Open Time Series framework.\nBecause an active community is crucial to keep the project sustainable, i.e., well maintained, we chose the R Project for Statistical Computing as our main programming language for the implementation of the framework. With its annual user conferences (Joo et al. 2022) and vibrant local communities1, R is known for its large and inclusive community. Alongside its strong regional and international community, the fact that R is open source and free of license costs lowers the barrier to entrance and contribution considerably. In addition, R offers well-established boiler plating ecosystems like usethis (Wickham et al. 2023) and documentation frameworks such as pkgdown (Wickham, Hesselberth, and Salmon 2022) or Roxygen (Wickham et al. 2022).\nWP1 focuses on the homogenization of the data ingestion process across datasets and data providers. In the first implementation step, we identify common parts of the ingestion process. We bundle these common parts in an R package that forms our core library and fosters reuse of source code. We encourage the community to use our core packages and to contribute by adding further dataset-specific packages. To inspire contributions, we supplement the Open Time Series framework’s core, based on our long-term experience as consumers of public data, with provider-specific ingestion libraries written in R that cover dataset idiosyncrasies.\n\n\n\nExample of a traditional official data publication of the Swiss GDP. Source: SECO, https://www.seco.admin.ch/seco/en/home/wirtschaftslage—wirtschaftspolitik/Wirtschaftslage/bip-quartalsschaetzungen-/daten.html accessed on February 12, 2024.\n\n\nThe above screenshot shows a traditional data publication of an official GDP statistic. Its use of multiple worksheets, empty lines and multi-line headers hampers machine readability. Like many regular consumers of the information contained in this spreadsheet, KOF sources this information immediately after its publication.\n\n\n\nScreenshot of a machine-readable data file, processed by an R-based engine.\n\n\nTo have a homogeneous, machine-readable representation of the data, we split this information into two files: based on the Comma Separated Values (CSV) on the web idea by the World Wide Web Consortium (W3C), we use a long format CSV file for the data and a Javascript Object Notation (JSON) file for the metadata. The metadata file takes advantage of the JSON format’s ability to handle nested data to store comprehensive, multilingual meta information. Our collaboration with the Secretariat of Economic Affairs led to a pioneering pilot publication of machine-readable data on the official SECO website: Machine-readable data is published as a complement to the traditional GDP publication2.\n\n\n\nExcerpt of the corresponding metadata file in JSON format.\n\n\nAt the end of WP1, we plan to iterate over the resulting datasets and data descriptions and enhance meta information where necessary. We will do this in a reproducible and transparent way by adding all changes to the source code that produces the data and metadata files."
  },
  {
    "objectID": "ord_plan.html#wp2-publication",
    "href": "ord_plan.html#wp2-publication",
    "title": "2  ORD Project Plan",
    "section": "2.3 WP2: Publication",
    "text": "2.3 WP2: Publication\n\n\n\n\n\n\n\n\n\nActivities and Research Questions\n\n\n\nActivity 2.1: Publication of Data Processing Framework\nActivity 2.2: Publish Containerized Runtime Setup\nActivity 2.3: Publish Data Processing and Revision Monitor\nActivity 2.4: Publication of Time Series Datasets for Scientific Use\nRQ 2.1: Which publication channels foster reuse of our code in other fields?\nRQ 2.2: How can we facilitate the deployment of our setup in other environments?\nRQ 2.3: Which information on data revisions and processing does the scientific (forecasting) community need to benchmark their work?\nRQ 2.4: How can we facilitate deployment of our setup in other environment?\n\n\nThe goal of Work Package 2 (WP2) is to find the platforms that suit our community, data and code components best and facilitate our approach to ORD. We will involve our data consumers and collaborators into this decision-making process. Based on our open by default thinking, we will publish not only the resulting time series data and meta information, but all components of our software framework. In the process, we will work together with the ETH legal service to find the most suitable open source licensing solution3 for all components of the opents project.\nThe Open Time Series project approach we suggest, splits data and meta information into two separate text files and formats: a simple CSV spreadsheet and a nested JSON file for multilingual data description. Having two simple text files per dataset allows us to disseminate the resulting time series data on free, standard infrastructure such as GitHub, which is well established in the open-source community. The state-of-the-art rendering of CSV spreadsheets on modern Git platforms sets the barrier to exploring and consuming our scientific use time series datasets as low as possible. Hence, the publication of data on GitHub, possibly using git’s Large File Storage (LFS) extension, forms our baseline scenario. Yet, in WP2, we will explore the feasibility of other, complementary, regional and international publication channels such as opendata.swiss4, r-universe or Zenodo.\nTechnically, the Open Time Series framework consists of a core R package and several data provider-specific ingestion packages. Again, we see the publication of all these components as open-source libraries on GitHub (or another major Git platform with good visibility) as the baseline form of publication. In addition, WP2 explores which of our components are suitable for publication on the Comprehensive R Archive Network (CRAN). Publication on CRAN comes with requirements and quality control but opens up our work to a larger audience so that endusers face the lowest possible hurdle to installing our packages.\n\n\n\nDownload of R packages from CRAN is very convenient in all major R environments. The screenshot above shows an example of RStudio’s graphical user interface for searching and downloading packages.\n\n\nWe will also explore more recent and experimental approaches, such as r-universe which helps to improve our reach in the data science community. In WP2, we aim to submit our work to an rOpenSci (Ram et al. 2019) peer review. rOpenSci shares our values of open and reproducible research through reuse and helps us reach ORD excellence."
  },
  {
    "objectID": "ord_plan.html#wp3-facilitate-usage-and-applications",
    "href": "ord_plan.html#wp3-facilitate-usage-and-applications",
    "title": "2  ORD Project Plan",
    "section": "2.4 WP3: Facilitate Usage and Applications",
    "text": "2.4 WP3: Facilitate Usage and Applications\n\n\n\n\n\n\n\n\n\nActivities and Research Questions\n\n\n\nActivity 3.1: Integrate Open Time Series Framework and Data into Hacking for Science Courses\nActivity 3.2: Organization of a Community Event\nRQ 3.1: What degree of data engineering literacy do scholars from different fields of research need?\nRQ 3.2: Future Outlook – What are the next steps to extend opents to other fields?\n\n\nThe goal of work package 3 (WP3) is to promote usage of the framework and data as well as to encourage others to contribute. In particular we are looking for community contributions such as maintenance of existing datasets, addition of public datasets that have not been processed yet and community activities. At this stage, we will also intensify activities to explore the expansion of Open Time Series into other academic fields.\nWe plan to reach the above goals in three ways: i) integration of Open Time Series data and software into academic teaching aimed at scientists from different disciplines. ii) presentation of Open Time Series at useR! 2024 in Salzburg, Austria5. iii) participation in local community events iv) hosting of an own event at KOF.\nStarting in fall 2024, Open Time Series data and software will be integrated into the Hacking for Science course6 given at ETH. Originally created for ETHZ D-MTEC PhD students, Hacking for Science is a highly interactive online course whose big picture guidance and hands-on software development approach attracts students from a great variety of fields. The course’s last iteration welcomed students from more than 10 different ETH departments as well as guests from outside ETH. We aim to communicate the value of open data to this broad audience and learn which challenges ORD faces in different fields. Currently, we also explore the possibility of running Hacking for Research Assistants – a satellite event for research assistants. In addition our teaching is complemented by the Research Software Engineering and Economic Data (RSEED) workshop series started in early 2024 which gives us an additional channel to promote an ORD mindset.\nStarting with the submission of Open Time Series to useR! 2024, we plan further activity at conferences and community events. At ETH, the Scientific Computing group has recently founded a Research Software Engineering (RSE) group7 to connect software engineers in science at ETH. Regular RSE events at ETH as well as the vibrant, local open source and opendata community8 will give us a chance to present the Open Time Series project, e.g., at the RSE group or the local R user group. KOF hosted useR! in 2021 and is well connected to the R community. This history and connections give a great chance to successfully apply for hosting an existing special interest conference such as R in Official Statistics at KOF. Hosting a well-established, smaller special interest conference allows us to give the entire event an ORD focus promote ORD thinking in official statistics.\n\n\n\n\nBannert, Matthias. 2024 forthcoming. Research Software Engineering - a Guide to the Open Source Ecosystem. CRC Data Science. CRC/Chapman & Hall.\n\n\nJoo, Rocı́o, Andrea Sánchez-Tapia, Sara Mortara, Yanina Bellini Saibene, Heather Turner, Dorothea Hug Peter, Natalia Soledad Morandeira, et al. 2022. “Ten Simple Rules to Host an Inclusive Conference.” PLoS Computational Biology. Public Library of Science.\n\n\nRam, Karthik, Carl Boettiger, Scott Chamberlain, Noam Ross, Maëlle Salmon, and Stefanie Butland. 2019. “A Community of Practice Around Peer Review for Long-Term Research Software Sustainability.” Computing in Science & Engineering 21 (2): 59–65. https://doi.org/10.1109/MCSE.2018.2882753.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher. 2023. Usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster. 2022. Roxygen2: In-Line Documentation for r. https://CRAN.R-project.org/package=roxygen2.\n\n\nWickham, Hadley, Jay Hesselberth, and Maëlle Salmon. 2022. Pkgdown: Make Static HTML Documentation for a Package. https://CRAN.R-project.org/package=pkgdown."
  },
  {
    "objectID": "impact.html#sustainability-in-the-eth-domain",
    "href": "impact.html#sustainability-in-the-eth-domain",
    "title": "3  Impact",
    "section": "3.1 Sustainability in the ETH Domain",
    "text": "3.1 Sustainability in the ETH Domain\nPushing an ORD approach at the KOF Swiss Economic Institute, which has a leading role in the field of economics in Switzerland and is an important monitor of the Swiss economy, will help advance ORD practices in empirical economics and official statistics in the long term. The use of the Open Time Series framework in teaching and monitoring work that involves official statistics will help the digital transformation process in official statistics through the education of future researchers and public servants who become familiar with Swiss official statistics data and ORD principles alike. In addition, our inclusive approach helps to keep the community involved, while the idea of modular software packages with maintainers at the dataset level allows hand over maintenance responsibilities in case of changes in personnel. The Comprehensive R Archive Network (CRAN) and the R Project for Statistical Computing have a long tradition at ETH. The ETH domain and its staff contributed substantially to the language and its extension packages, including to CRAN itself1."
  },
  {
    "objectID": "impact.html#solving-a-critical-problem",
    "href": "impact.html#solving-a-critical-problem",
    "title": "3  Impact",
    "section": "3.2 Solving a Critical Problem",
    "text": "3.2 Solving a Critical Problem\nAlthough there has been a certain sense of urgency for digital transformation in the public sector at least since the pandemic, change management within large institutions does not always align with the timeline of individual academic careers or ongoing daily business. While we greatly appreciate advances in making official statistics available through application programming interfaces (API), as well as investment into community exchange, we provide an immediate solution to data sourcing to those that need to source public data today. In addition, we help identify redundant efforts across institutions and broker the usage of common sources which entails using public money more efficiently. Finally, we help bridge the gap and strengthen the link between public administration and academic research. Our addition of time series to the Swiss data landscape lifts the state-of-the-art by facilitating intertemporal comparison and real-time analysis."
  },
  {
    "objectID": "impact.html#collaborative-approach",
    "href": "impact.html#collaborative-approach",
    "title": "3  Impact",
    "section": "3.3 Collaborative Approach",
    "text": "3.3 Collaborative Approach\nThe proposed Open Time Series project is highly collaborative in multiple ways. The technical approach is inclusive and modular. Through open-sourcing and focusing on the core package, we hold ourselves accountable through the community and, at the same time, encourage contribution to the technical core. In our data provider-specific modules, we foster collaboration at the dataset level. Through our own dataset modules, we provide examples that collaborators from other fields can use – along with the documentation – as blueprints to build their own extension packages to process data from their respective fields. Finally, we involve data providers from the very start of the project. Our goal is to use our traditional ties with federal and regional public administration to establish a channel for hands-on, two-way feedback between data providers and the research community. In the process, we plan to take part in existing academic and non-academic community events and explore new ways and formats, particularly in a kind of teaching that involves students in our collaborative approach."
  },
  {
    "objectID": "impact.html#fair-principles",
    "href": "impact.html#fair-principles",
    "title": "3  Impact",
    "section": "3.4 FAIR Principles",
    "text": "3.4 FAIR Principles\nThe Open Time Series project aims at making its output findable. We combine our own experience with the expertise and reach of our partners to find the optimal outlets to help us reach multiple communities. A high degree of automation allows us to consider and maintain multiple platforms, from GitHub to CRAN for our software and from Dryad2 to opendata.swiss and Zenodo3 for our datasets.\nAs stated before, we intend to subject our work to a scientific software review (Ram et al. 2019) by the renowned rOpenSci (Boettiger et al. 2015) organization.\n\nrOpenSci fosters a culture that values open and reproducible research using shared data and reusable software – https://ropensci.org/about/, accessed on February 12, 2024.\n\nWe make our work accessible. With the support of ETH Legal Services, we will open-source our software and will find appropriate open-source and creative common licenses for our software and data.\nWe will not make any compromise when it comes to making our data interoperable. We will build on the World Wide Web Consortium’s (W3C) idea of CSV on the Web4, setting the tone for interoperability. Like CSVW, our data output will split data and metadata into two files: a data CSV file and a metadata JSON file. We will use standard CSV files for time series to not only allow virtually any programming language to process them but also ensure that standard office software can read our data. Our JSON metadata files extend the basic idea of the W3C. We will use a key to refer to data and allow the storage of comprehensive, multilingual meta-information.\nA reusable and extendable framework and data pool of macroeconomic time series will be a core contribution of the Open Time Series project. We will not only provide the data and software as is; we will also provide community support on our GitHub page and Research Software Engineering and Economic Data (RSEED) matrix chat space. In addition, we use the project as a teaching example and ambassador for the FAIR principles among ETH students.\n\n\n\n\nBoettiger, Carl, Scott Chamberlain, Edmund Hart, and Karthik Ram. 2015. “Building Software, Building Community: Lessons from the Ropensci Project.” Journal of Open Research Software 3. https://doi.org/10.5334/jors.bu.\n\n\nRam, Karthik, Carl Boettiger, Scott Chamberlain, Noam Ross, Maëlle Salmon, and Stefanie Butland. 2019. “A Community of Practice Around Peer Review for Long-Term Research Software Sustainability.” Computing in Science & Engineering 21 (2): 59–65. https://doi.org/10.1109/MCSE.2018.2882753.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al. 2016. “The FAIR Guiding Principles for Scientific Data Management and Stewardship.” Scientific Data 3 (1): 160018. https://doi.org/10.1038/sdata.2016.18."
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "4  Schedule Overview",
    "section": "",
    "text": "The following Gantt chart shows the four work packages (WP0: Coordination and Planning, WP1: Make Data Processing Framework Inclusive, WP2: Publication and WP3: Facilitate Usage and Applications) and the timeframe in which activities will be carried out. See Sections 2.1 - 2.4 above for details on the goals and implementation of the WPs. The chart also includes the project activities and giving an overview of which activity is led by which collaborator, where PI = Principal Investigator, RSE = Research Software Engineer, and SA = Scientific Assisstant, PA = Programming Assistant, ZD = KOF Swiss Economic Institute (KOF) IT specialist (‘Zentrale Dienste’).\n\n\n\nSchedule overview"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bannert, Matthias. 2024 forthcoming. Research Software Engineering -\na Guide to the Open Source Ecosystem. CRC Data Science. CRC/Chapman\n& Hall.\n\n\nBoettiger, Carl, Scott Chamberlain, Edmund Hart, and Karthik Ram. 2015.\n“Building Software, Building Community: Lessons from the Ropensci\nProject.” Journal of Open Research Software 3. https://doi.org/10.5334/jors.bu.\n\n\nJoo, Rocı́o, Andrea Sánchez-Tapia, Sara Mortara, Yanina Bellini Saibene,\nHeather Turner, Dorothea Hug Peter, Natalia Soledad Morandeira, et al.\n2022. “Ten Simple Rules to Host an Inclusive Conference.”\nPLoS Computational Biology. Public Library of Science.\n\n\nRam, Karthik, Carl Boettiger, Scott Chamberlain, Noam Ross, Maëlle\nSalmon, and Stefanie Butland. 2019. “A Community of Practice\nAround Peer Review for Long-Term Research Software\nSustainability.” Computing in Science & Engineering\n21 (2): 59–65. https://doi.org/10.1109/MCSE.2018.2882753.\n\n\nWickham, Hadley, Jennifer Bryan, Malcolm Barrett, and Andy Teucher.\n2023. Usethis: Automate Package and Project Setup. https://CRAN.R-project.org/package=usethis.\n\n\nWickham, Hadley, Peter Danenberg, Gábor Csárdi, and Manuel Eugster.\n2022. Roxygen2: In-Line Documentation for r. https://CRAN.R-project.org/package=roxygen2.\n\n\nWickham, Hadley, Jay Hesselberth, and Maëlle Salmon. 2022. Pkgdown:\nMake Static HTML Documentation for a Package. https://CRAN.R-project.org/package=pkgdown.\n\n\nWilkinson, Mark D., Michel Dumontier, IJsbrand Jan Aalbersberg,\nGabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, et al.\n2016. “The FAIR Guiding Principles for Scientific Data Management\nand Stewardship.” Scientific Data 3 (1): 160018. https://doi.org/10.1038/sdata.2016.18."
  }
]